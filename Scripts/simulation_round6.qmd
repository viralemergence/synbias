---
title: "Coinfection bias simulations: round 6"
format: html
---

```{r setup}
library(poems)
library(tidyverse)
library(furrr)
library(Rcpp)
library(qs)
library(here)
library(data.table)
library(mgcv)
library(gratia)
library(parallel)
library(ggpointdensity)
# library(parglm)
library(cowplot)
library(paletteer)
source(here("Scripts/simulation_functions.R"))
sourceCpp(here("Scripts/ferrari.cpp"))
options(future.globals.maxSize= 9967869120)
theme_set(theme_cowplot())
data_dir <- here("Data/simulation_round6")
simulate <- FALSE
run_gam <- FALSE
```

# Rationale

In this round of simulations, I am trying out a new approach. Previously, we generated pairwise interactions between strains using a C:F ratio to divide matrices between competition and facilitation, then interaction strength to determine the bounds of the uniform distribution of competition and facilitation from which the values would be drawn. This time, we will generate pairwise interactions from a normal distribution, with the CF ratio shaping the mean and interaction strength shaping the SD. The actual outbreak simulations, and all other aspects, remain the same.

# Generate inputs

```{r generate inputs}
set.seed(1800)
DFList <- 
  1:10000 %>% 
  map(function(a){
    
    data.frame(id = a, 
               interaction_strength = runif(1, 0, 0.3),
               cf_ratio = runif(1, 0.7, 1.3),
               priority_effects = F,
               strains = round(runif(1, 5, 100)), 
               sample_prop = runif(1, 0.1, 1))
    
  })
inputs <- DFList %>%
  map(function(df) {
    int_matrix <- matrix(1, nrow = df$strains, ncol = df$strains)
    int_matrix[] <- rnorm(n = df$strains*df$strains, mean = df$cf_ratio, sd = df$interaction_strength)
    diag(int_matrix) <- 1
    initial_pop <- c(rep(c(1, rep(0, df$strains)), df$strains),
                    rep(0, df$strains*1000 - df$strains*(df$strains+1))) |>
      matrix(nrow = 1000, byrow = T)
    return(list(initial_pop = initial_pop, interactions = int_matrix))
  })
strainDF <- inputs %>% 
  map("interactions") |>
  map(function(a){
    
    Comp <- a
    Comp[Comp > 1] <- 0
    Comp <- abs(Comp-1)
    Comp[Comp == 1] <- 0
    
    Fac <- a
    Fac[Fac < 1] <- 0
    Fac <- Fac-1
    Fac[Fac == -1] <- 0
    
    diag(Comp) <- diag(Fac) <- 0
    
    data.frame(CompStrength = rowSums(Comp),
               FacStrength = rowSums(Fac),
               CompMeans = rowMeans(Comp),
               FacMeans = rowMeans(Fac),
               Strain = 1:nrow(a))
    
  }) %>% bind_rows(.id = "id") %>% 
  mutate(id = as.numeric(id)) |>
  left_join(DFList |> bind_rows()) |>
  mutate(TotalStrength = CompStrength + FacStrength, 
                   TotalMean = CompMeans + FacMeans)

summary(strainDF)
write_csv(strainDF, here("Data/simulation_round6/simulation_round6_inputs.csv"))
setDT(strainDF)

fig1a <- strainDF %>% slice_sample(n = 10000) %>% 
  ggplot(aes(CompStrength, FacStrength)) + 
  geom_pointdensity() +
  scale_size_continuous(name = "Strains") +
  scale_color_paletteer_c(name = "Density",
                          palette = "grDevices::Cividis") +
  lims(x = c(0, NA), y = c(0, NA)) +
  coord_fixed() +
  xlab("Facilitation Strength") + 
  ylab("Competition Strength")
fig1b <- strainDF |> 
  slice_sample(n = 10000) %>% 
  ggplot(aes(CompStrength, FacStrength)) + 
  geom_point(aes(col = strains)) +
  lims(x = c(0, NA), y = c(0, NA)) +
  coord_fixed() +
  xlab("Facilitation Strength") + 
  ylab("Competition Strength") +
  scale_color_paletteer_c(name = "# of Strains",
                          palette = "pals::cubicyf")
fig1 <- plot_grid(fig1a, fig1b, ncol = 1, labels = "AUTO")
ggsave(here("Figures/Fig 1 input distribution v2.png"))
```

# Simulate

```{r simulate}
if (simulate) {
  future_walk(1:length(inputs), \(x) {
    filename <- paste0(getwd(),
                       "/Data/simulation_round6/sim",
                       sample_data6$id[x],
                       ".qs")
    if (!file.exists(filename)) {
      sourceCpp("Scripts/ferrari.cpp")
      x <- inputs[[x]]
      mat <- ferrari(x$initial_pop, x$interactions, 2e-04, 100)
      qsave(mat, filename)
    }
  }, .progress = T)
}
```

# Sample

```{r sample}
disease_sample <- function(sim_number, prop) {
  matrix <- file.path(data_dir, paste0("sim", sim_number, ".qs")) |> 
    qread()
  individuals <- round(prop*nrow(matrix))
  df <- map(1:100, ~matrix[sample(1:nrow(matrix), individuals), , .]) |>
    abind::abind(along = 3) |> 
    colSums() |> 
    apply(c(1,2), as.logical) |> 
    array_branch(1) |> 
    map(\(dt) data.table(detect = dt, time = 1:100)) |> 
    map2(strainDF[id == sim_number] %>% split(seq_len(nrow(.))), cbind) |> 
    rbindlist()
  gc()
  return(df)
}
plan(sequential)
detect_df <- future_map(1:10000, \(i) disease_sample(i, DFList[[i]]$sample_prop)) |>
  rbindlist()

```

# Analyze

## 50% prevalence timepoint

It is important for us to understand the timepoint at which strains reach 50% prevalence, on average, so we get a sense of the range of timepoints that have realistic prevalences.

```{r 50 percent prevalence}
prevalence50 <- function(path) {
  path |> qread() |>
    apply(c(2, 3), sum) |>
    array_branch(1) |>
    map(\(x) x >= 500) |>
    map_int(match, x = TRUE)
}
plan(multisession, workers = 4)
timepoints <- 1:10000 |>
  map(\(x) paste0(data_dir, "/sim", x, ".qs")) |>
  future_map(prevalence50, .progress = T)
timepoints |> flatten_int() |>
  hist(main = "Histogram of 50% prevalence points",
       xlab = "Timestep when prevalence is 50%")
```

## GAM

To check for nonlinearities.

```{r gam}
if (run_gam) {
  tensor_gam <- bam(detect ~ te(CompMeans, FacMeans) + s(strains) + s(sample_prop),
                  family = binomial(), data = detect_df,
                  cluster = makeCluster(2))
  draw(tensor_gam)
} else {
  tensor_gam <- qread(here("Data/Analysis/tensor_gam.qs"))
}
sm <- smooth_estimates(tensor_gam, 
                       data = detect_df |> 
                         select(CompMeans, FacMeans, strains, sample_prop) |> 
                         unique() |> slice_sample(n = 20000))
sample_prop_plot <- sm |> filter(.smooth == "s(sample_prop)") |> 
  ggplot(aes(x = sample_prop)) + 
  geom_line(aes(y = .estimate)) +
  ylab("Partial effect on detectability") +
  xlab("Proportion of population sampled") +
  xlim(0, 1)
# Compute suitable width and height for tiles
width <- (max(sm$FacMeans, na.rm = T) - min(sm$FacMeans, na.rm = T)) / 50
height <- (max(sm$CompMeans, na.rm = T) - min(sm$CompMeans, na.rm = T)) / 50
sm_filtered <- sm |> filter(.smooth == "te(CompMeans,FacMeans)")

tensor_smooth <- ggplot(sm |> filter(.smooth == "te(CompMeans,FacMeans)"), 
       aes(x = FacMeans, y = CompMeans, fill = .estimate)) +
  geom_tile(width = width, height = height) +
  scale_fill_gradient2(low = "#1C65A3FF", high = "#CD4101FF", 
                       mid = "#CACACAFF", midpoint = 0, 
                       limit = c(min(sm_filtered$.estimate), max(sm_filtered$.estimate)),
                       name = "Effect on\ndetectability") +
  xlab("Mean Facilitation") +
  ylab("Mean Competition")

plot_grid(sample_prop_plot, tensor_smooth, ncol = 1, labels = "AUTO")
save_plot(here("Figures/Fig 2 GAM results v2.png"), last_plot(),
          base_height = 7, base_asp = 0.8)
```

## GLM

The behavior of the predictors does not look too far from linear, so I will go ahead and do some GLMs. Here is an analysis where I include population as a random effect and competition and facilitation as interactions with time.

```{r glm}
if (run_gam) {
  detect_glm <- parglm(detect ~ time + time:CompMeans + time:FacMeans + strains +
                sample_prop,
            data = detect_df,
            family = binomial, 
            control = parglm.control(nthreads = 3L))
} else {
  detect_glm <- qread(here("Data/Analysis/detect_glm.qs"))
}

# Create a dataframe for the coefficients
coefs <- coef(detect_glm)
se <- sqrt(diag(vcov(detect_glm)))
alpha <- 0.05
z <- qnorm(1 - alpha / 2)
lower_bound <- coefs - z * se
upper_bound <- coefs + z * se
ci <- data.frame(
  Estimate = coefs,
  Lower = lower_bound,
  Upper = upper_bound
) |> rownames_to_column("Term")

# Plotting
ggplot(ci, aes(x = Term, y = Estimate, fill = Estimate > 0)) +
  geom_col() +
  coord_flip() +
  labs(title = "GLM Coefficients", x = "Terms", y = "Coefficient Value") +
  scale_fill_manual(values = c("red", "blue"), name = "Effect", labels = c("Negative", "Positive")) +
  theme_minimal_vgrid()

ggsave(here("Figures/Fig 3 GLM coefs v1.png"))

# Generate a grid of values for 'time' and 'CompMeans'
time_values <- seq(min(detect_df$time), max(detect_df$time), length.out = 100)
comp_means_values <- seq(min(detect_df$CompMeans), max(detect_df$CompMeans), length.out = 100)

# Create a grid for prediction
prediction_grid <- expand.grid(time = time_values, CompMeans = comp_means_values)

# Assume mean values for other predictors for simplicity
mean_strains <- mean(detect_df$strains)
mean_fac_means <- mean(detect_df$FacMeans)

# Add constant predictors
prediction_grid$strains <- mean_strains
prediction_grid$sample_prop <- 0.1
prediction_grid$FacMeans <- mean_fac_means

# Predict over the grid
prediction_grid$Predicted <- predict(detect_glm, newdata = prediction_grid, type = "response")

# Plot
p1 <- ggplot(prediction_grid, aes(x = time, y = CompMeans, fill = Predicted)) +
  geom_tile(aes(fill = Predicted)) + 
  scale_fill_paletteer_c("grDevices::Mako",
                       name = "Probability", direction = -1) +
  geom_contour(aes(z = Predicted)) +
  labs(title = "Interaction Effect of Time and Competition", 
       x = "Time", y = "Mean Competition")

# Generate a grid of values for 'time' and 'FacMeans'
time_values <- seq(min(detect_df$time), max(detect_df$time), length.out = 100)
fac_means_values <- seq(min(detect_df$FacMeans), max(detect_df$FacMeans), length.out = 100)

# Create a grid for prediction
prediction_grid <- expand.grid(time = time_values, FacMeans = fac_means_values)

# Assume mean values for other predictors for simplicity
mean_strains <- mean(detect_df$strains)
mean_comp_means <- mean(detect_df$CompMeans)

# Add constant predictors
prediction_grid$strains <- mean_strains
prediction_grid$sample_prop <- 0.1
prediction_grid$CompMeans <- mean_comp_means

# Predict over the grid
prediction_grid$Predicted <- predict(detect_glm, newdata = prediction_grid, type = "response")

# Plot
p2 <- ggplot(prediction_grid, aes(x = time, y = FacMeans)) +
  geom_tile(aes(fill = Predicted)) + 
  scale_fill_paletteer_c("grDevices::Mako",
                       name = "Probability", direction = -1) +
  geom_contour(aes(z = Predicted)) +
  labs(title = "Interaction Effect of Time and Facilitation", 
       x = "Time", y = "Mean Facilitation")

plot_grid(p1, p2, ncol = 1, labels = "AUTO")
save_plot(here("Figures/Fig 4 Time interactions v2.png"), last_plot(), 
          base_asp = 0.7, base_height = 8)
```
