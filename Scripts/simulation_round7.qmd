---
title: "synbias simulations: Round 7"
author: "July Pilowsky"
format: html
---

# Goal

To run simulations of coinfection in a host population and determine how interactions between coinfecting strains affect detectability of these strains through imperfect sampling. This round of simulations will include full stratified sampling of all epidemiological parameters, false negative and false positive rates, as well as the balanced sampling of possible species interactions found in previous rounds. This round will be run in Julia using my package `CoinfectionSimulator.jl`.

```{julia setup}
using CoinfectionSimulator
using LatinHypercubeSampling
using DataFrames
using Random
using Distributions
using CSV
using Tables
using Tidier
using MLJ
using TidierPlots
using BetaML
using Shapley
Random.seed!(18)
n_sims = 10000
```

# Simulation setup

## Parameters

The following parameters will change across simulations and will be sampled in a stratified manner:

1.  Interaction strength (between strains), 0 - 0.5
2.  Competition:facilitation ratio, 0.2 - 0.8
3.  Number of strains, 5 - 50
4.  Proportion of the population sampled, 0 - 1
5.  False negative rate, 0 - 0.5
6.  Disease-induced mortality, 0 - 0.5
7.  Transmission, 0 - 0.1
8.  Latency, 1 - 20
9.  Recovery, 0 - 0.1

```{julia variables}
plan, _ = LHCoptim(n_sims, 9, 10)
scaled_plan = scaleLHC(plan, [(0, 0.5), (0.2, 0.8), (5, 50), (0, 1),
    (0, 0.5), (0, 0.5), (0, 0.1), (1, 20), (0, 0.1)])
```

The following parameters will remain constant across all simulations:

1.  Priority effects (all simulations will have priority effects)
2.  False positive rate (0 across all simulations)
3.  Initial population size (1000 individuals)
4.  Disease type (will always be SEIR)
5.  Baseline host mortality (always 0)
6.  Host fecundity (always 0)
7.  Number of time steps (always 100)
8.  Introduction of strains (always simultaneous at the first timestep)

## Prep interaction matrices

I can create interaction matrices for all the simulations using the `prep_interaction_matrix` function from `CoinfectionSimulator.jl`.

```{julia prep interaction matrices}
input_df = DataFrame(
    interaction_strength=scaled_plan[:, 1],
    cf_ratio=scaled_plan[:, 2],
    priority_effects=trues(n_sims),
    strains=round.(Int, scaled_plan[:, 3]),
    proportion_sampled=scaled_plan[:, 4],
    false_negative=scaled_plan[:, 5],
    disease_mortality=scaled_plan[:, 6],
    transmission=scaled_plan[:, 7],
    latency=scaled_plan[:, 8],
    recovery=scaled_plan[:, 9],
)
CSV.write("Data/simulation_round7_input.csv", input_df)
matrices = create_interaction_matrix(input_df)
```

# Simulation

```{julia simulate}
input_df = CSV.read("Data/simulation_round7_input.csv", DataFrame)
matrices = create_interaction_matrix(input_df)
n_individuals = 1000

# Collect detection vectors
results = zeros(n_sims, 100)

# Simulate
for i in 1:n_sims
    # Create SEIR strains
    n_strains = Int(input_df.strains[i])
    strains = Vector{SEIRModel}(undef, n_strains)
    for i in 1:n_strains
        strains[i] = SEIRModel(
            rand(Truncated(Normal(input_df.transmission[i], 1), 0, 1)),
            rand(Truncated(Normal(input_df.disease_mortality[i], 1), 0, 1)),
            rand(Truncated(Normal(input_df.recovery[i], 1), 0, 1)),
            round(Int, rand(Truncated(Normal(input_df.latency[i], 1), 1, 10)))
        )
    end
    # Initialize population - everyone starts susceptible
    initial_pop = Population(Individual[])
    for i in 1:n_individuals
        individual = Individual(n_strains, 1)  # age 1
        push!(initial_pop.individuals, individual)
    end
    # Set simulation parameters
    params = SimulationParameters(
        strains,
        matrices[i],
        0.0, # base mortality
        0.0, # fecundity
        1, # Age of maturity
        :simultaneous, # introduction of strains
        100, # time steps
        :density # transmission type
    )

    true_pop = simulate(initial_pop, params)

    sampling_params = SamplingParameters(
        input_df.proportion_sampled[i],
        0.0, # false positive
        input_df.false_negative[i],
    )

    detections = sample_populations(true_pop, sampling_params)

    results[i, :] = sum(detections, dims=2)
end

CSV.write("Data/simulation_round7_output.csv",
    Tables.table(results),
    writeheader=false)
```

# Analysis

To analyze the results, I first need to pair them up with the input parameters that produced them.

```{julia analysis dataset}
# Read the data back in
input_parameters = @chain CSV.read("Data/simulation_round7_input.csv", DataFrame) begin
    @mutate(sim = 1:10000) # simulation IDs
end
simulation_output = @chain CSV.read("Data/simulation_round7_output.csv", DataFrame, header=false) begin
    @mutate(sim = 1:10000) # simulation IDs
    @pivot_longer(cols = 1:100,
        names_to = "timestep",
        values_to = "Detections")
    transform!(:timestep => ByRow(x -> parse(Int, replace(x, "Column" => ""))) => :timestep)
    @left_join(input_parameters, sim) # add input parameters
    @mutate(error_rate = abs(strains - Detections) / strains) # calculate error rate
end

for col in names(simulation_output)
    if eltype(simulation_output[!, col]) >: Missing
        # Remove Missing from the column type
        simulation_output[!, col] = identity.(simulation_output[!, col])
    end
end

ggplot(simulation_output) +
geom_histogram(aes(x=:error_rate), bins=50) +
scale_y_log10()
```

It seems that most of the samples result in no detections, which is to say an error rate of 1. This is likely because a SEIR model with no demography will often result in a disease that burns itself out fairly quickly, so there are no strains to detect after a certain point in the simulations.

Now I will use a machine learning algorithm to find which input parameters affect the error rate the most.

```{r analyze simulation output}
library(data.table)
library(here)
library(tidymodels)
library(stringr)
library(vip)
library(future)
plan(multicore)

input_parameters <- fread(here("Data/simulation_round7_input.csv"))[, -c("priority_effects")][, sim := 1:10000]
simulation_output <- fread(here("Data/simulation_round7_output.csv"))[, sim := 1:10000] |>
    melt(data = _, id.vars = "sim", measure_vars = 1:100, variable.name = "timestep", value.name = "Detections") |>
    _[, timestep := as.numeric(str_sub(timestep, 2))] |>
    merge(x = _, y = input_parameters, by = "sim") |>
    _[, error_rate := abs(strains - Detections) / strains]
synbias_split <- initial_split(simulation_output[, -c("sim", "Detections")], strata = error_rate)
synbias_train <- training(synbias_split)
synbias_test <- testing(synbias_split)
tune_spec <- boost_tree(
    # trees = tune(),
    # min_n = tune(),
    # learn_rate = tune(),
    # tree_depth = tune(),
    # loss_reduction = tune(),
    # sample_size = tune(),
    # mtry = tune(),
) |>
    set_engine("xgboost") |>
    set_mode("regression")
# synbias_folds <- vfold_cv(synbias_train, 4)
# synbias_res <- workflow() |>
#     add_model(tune_spec) |>
#     add_formula(error_rate ~ cf_ratio * interaction_strength + timestep + strains + proportion_sampled + false_negative + disease_mortality + transmission + latency + recovery) |>
#     tune_grid(
#         resamples = synbias_folds
#     )
# best_tree <- synbias_res |> select_best(metric = "rmse") # trees = 1555, min_n = 23, learn_rate = 0.316, tree_depth = 10, loss_reduction = 1.90e-9, sample_size = 1, mtry = 8
best_tree <- list(
    trees = 1555,
    min_n = 23,
    learn_rate = 0.316,
    tree_depth = 10,
    loss_reduction = 1.90e-9,
    sample_size = 1,
    mtry = 8,
    stop_iter = 1000
)
final_wf <- workflow() |>
    add_model(tune_spec) |>
    add_formula(error_rate ~ cf_ratio * interaction_strength + timestep + strains + proportion_sampled + false_negative + disease_mortality + transmission + latency + recovery) |>
    finalize_workflow(best_tree)
final_fit <- final_wf %>%
    last_fit(synbias_split)
final_fit %>%
    collect_metrics()
final_fit |>
    extract_workflow() |>
    extract_fit_parsnip() %>%
    vip()
```

In the end, a very interesting result. The strong effects of timestep, number of strains, false negative rate, and proportion sampled were expected. It's interesting that transmission is the most important epidemiological parameter in terms of the error rate on pathogen richness.

Let's examine this more closely using plots of Shapley values.

```{r shapley_plots}
# Create the model matrix using the same formula as workflow
formula <- error_rate ~ cf_ratio * interaction_strength + timestep + strains + proportion_sampled + false_negative + disease_mortality + transmission + latency + recovery
train_matrix <- synbias_test |>
    slice_sample(prop = 0.1) |>
    model.matrix(object = formula, data = _) |>
    _[, -1] # remove intercept

# Extract the xgboost model
xgb_model <- final_fit %>%
    extract_workflow() %>%
    extract_fit_parsnip() %>%
    .$fit

# Compute SHAP values
library(SHAPforxgboost)
shapley_data <- shap.values(xgb_model, as.matrix(train_matrix))
shap_long <- shap.prep(shap_contrib = shapley_data$shap_score, X_train = train_matrix)
shap.plot.summary(shap_long)

source(here("Scripts/shapley_plots.R"))
library(patchwork)
partial.dependence.plot(colnames(train_matrix), shap_long, as.data.frame(train_matrix), c("#4F6980FF", "#849DB1FF", "#A2CEAAFF", "#638B66FF", "#BFBB60FF", "#F47942FF", "#FBB04EFF", "#B66353FF", "#D7CE9FFF", "#B9AA97FF", "#7E756DFF"))
```